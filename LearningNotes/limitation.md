# Dainarx 算法限制与约束分析

> 本文档详细记录了 Dainarx 算法的各类限制、约束和假设，帮助用户理解算法的适用范围和边界条件。

## 前言

算法在运行时，配置参数从 JSON 文件中读取，这意味着算法的设计**依赖人类经验来进行一些提前的设置**。许多关键参数无法自动确定，需要领域知识或试验调优。本文档按照限制的类型和影响程度进行组织，每项限制都包含：位置、代码示例、技术原因和影响分析。

---

## 一、配置依赖性限制 (Configuration Dependencies)

### 1.1 NARX 模型阶数 (order) - 【关键】

**位置:** `main.py:33`, `src/DEConfig.py:67-76`

**限制:** NARX 差分方程的阶数必须人工指定，无法自动确定最优值。

**代码示例:**
```python
# main.py:33
FeatureExtractor(len(data_list[0]), len(input_data[0]),
                 order=config['order'],  # ← 必须预先设置，通常为 3-5
                 dt=config['dt'], minus=config['minus'],
                 need_bias=config['need_bias'], other_items=config['other_items'])
```

**技术原因:**
- NARX 模型形式为 `x[t] = f(x[t-1], ..., x[t-order], u[t])`，阶数决定了历史依赖的时间深度
- 缺少自动模型选择机制（如 AIC/BIC 准则）
- 需要领域知识或网格搜索来确定合适的阶数

**影响:** **关键 - 影响整个流程**
- **阶数过低:** 无法捕捉系统动态规律，拟合误差大，变点检测失败
- **阶数过高:** 过拟合训练数据，泛化性差，数值不稳定，计算复杂度增加
- **级联影响:** 变点检测、数据分割、聚类、守卫学习都依赖此参数的正确性

**参数选择建议:**
- 一阶系统: order = 2-3
- 二阶系统: order = 3-4
- 高阶非线性系统: order = 4-5
- 可通过交叉验证选择最优阶数

---

### 1.2 滑动窗口大小 (window_size) - 【关键】

**位置:** `src/ChangePoints.py:16-31`

**限制:** 变点检测的滑动窗口大小固定，默认值为 10，无自适应机制。

**代码示例:**
```python
# src/ChangePoints.py:16
def find_change_point(data: np.array, input_data: np.array, get_feature,
                      w: int = 10, merge_th=None):
    """w 参数控制窗口大小，默认 10"""
    if merge_th is None:
        merge_th = w  # 合并阈值也依赖窗口大小

    # 滑动窗口遍历
    while pos + w < data.shape[1]:
        feature, now_err, fit_order = get_feature(data[:, pos:(pos + w)],
                                                   input_data[:, pos:(pos + w)])
        if last is not None:
            if (max(now_err) > eps) and tail_len == 0:
                change_points.append(pos + w - 1)
                tail_len = w  # 跳过接下来的 w 个位置
```

**技术原因:**
- 窗口需要足够大以拟合 NARX 模型（至少 > order）
- 窗口大小影响变点检测的灵敏度和延迟
- 与数据采样率、模式持续时间、噪声水平都相关，难以统一设置

**影响:** **关键 - 直接影响变点检测质量**
- **窗口过小 (w < 5):** 对噪声敏感，产生大量虚假变点，过度分割
- **窗口过大 (w > 20):** 遗漏真实变点，检测延迟，变点位置不准确
- **无自适应:** 不同系统和数据段可能需要不同窗口大小，固定值难以适应

**参数选择建议:**
- 最小值: w ≥ order + 3
- 典型值: w = 10-15
- 快速切换系统: w = 5-8
- 噪声大的系统: w = 15-20

---

### 1.3 非线性项 (other_items) - 【关键】

**位置:** `main.py:33`, `src/DEConfig.py:54-65`

**限制:** 非线性项（如 `x[1]**3`, `sin(x[1])`）必须人为指定，系统不执行符号回归或自动特征发现。

**代码示例:**
```python
# main.py:33
FeatureExtractor(len(data_list[0]), len(input_data[0]),
                 order=config['order'], dt=config['dt'], minus=config['minus'],
                 need_bias=config['need_bias'],
                 other_items=config['other_items'])  # ← 必须预先知道系统的非线性形式

# 示例: Duffing 振子配置文件
{
    "config": {
        "other_items": "x[?] ** 3"  # 必须知道 Duffing 有立方非线性项
    }
}
```

**非线性项解析机制 (src/DEConfig.py:54-65):**
```python
@staticmethod
def analyticalExpression(expr_list: str, var_num, order):
    """将字符串表达式解析为可执行的 lambda 函数"""
    expr_list = expr_list.split(';')  # 分号分隔多个表达式

    for s in expr:
        # 核心：将字符串转换为 lambda 函数
        res[idx].append(eval('lambda x: ' + s))
        # 例如："x[0][1]*x[1][1]" → lambda x: x[0][1]*x[1][1]
```

**技术原因:**
- 需要领域知识了解系统的物理特性和非线性形式
- 符号回归计算代价高，且容易过拟合
- 当前设计通过字符串表达式 + eval() 实现可扩展性

**影响:** **关键 - 对非线性系统至关重要**
- **缺少关键项:** 无法拟合非线性动态，聚类失败，模式识别错误
- **添加错误项:** 过拟合，模型复杂度不必要增加
- **线性系统:** 可以不设置（other_items = ''）

**常见非线性项:**
- **多项式:** `x[1]**2`, `x[1]**3`, `x[2]**2`
- **交叉项:** `x[1]*x[2]`, `x[1]**2*x[2]`
- **三角函数:** `sin(x[1])`, `cos(x[1])`, `sin(x[1])*cos(x[2])`
- **指数:** `exp(x[1])` (需谨慎，容易数值溢出)

**示例配置:**
```python
# Duffing 振子: ẍ + δẋ + αx + βx³ = γcos(ωt)
"other_items": "x[?] ** 3"

# Van der Pol 振子: ẍ - μ(1-x²)ẋ + x = 0
"other_items": "x[1]**2; x[1]**2*x[2]"

# 摆: θ̈ + (g/l)sin(θ) = 0
"other_items": "sin(x[1])"
```

---

### 1.4 SVM 超参数 (svm_c, kernel, class_weight) - 【关键】

**位置:** `src/GuardLearning.py:39`

**限制:** SVM 的核函数类型、正则化参数 C 和类别权重需要手动调优，无自动超参数搜索。

**代码示例:**
```python
# src/GuardLearning.py:39
svc = SVC(C=config['svm_c'],           # 正则化参数，默认 1e6
          kernel=config['kernel'],      # 核函数: 'linear', 'rbf', 'poly'
          class_weight={0: config['class_weight'], 1: 1})  # 类别权重
```

**技术原因:**
- SVM 守卫学习的准确性高度依赖超参数选择
- 无网格搜索 (Grid Search) 或交叉验证机制
- 不同系统的最优超参数差异很大

**影响:** **关键 - 决定守卫边界质量**
- **C 过大 (>1e8):** 过拟合训练数据，守卫边界过于复杂，泛化性差
- **C 过小 (<1e2):** 欠拟合，守卫边界过于简单，无法捕捉真实条件
- **核函数选择错误:** 线性核无法处理非线性守卫，RBF 核可能过拟合

**核函数选择指南:**

| 核函数 | 适用场景 | 示例守卫条件 | 示例系统 |
|--------|---------|-------------|---------|
| `linear` | 线性守卫边界 | $x_1 + x_2 \leq c$ | 温控系统、简单开关系统 |
| `rbf` | 非线性守卫边界 | $x^2 + y^2 \leq r^2$ | Duffing 振子、弹跳球 |
| `poly` | 多项式守卫边界 | $x^3 - 2x \geq 0$ | 高阶非线性系统 |

**参数选择建议:**
- **C 参数:**
  - 干净数据: C = 1e4 - 1e6
  - 噪声数据: C = 1e2 - 1e4
  - 可通过交叉验证选择
- **核函数:**
  - 优先尝试 `rbf`（适用范围广）
  - 守卫已知为线性时用 `linear`
  - `poly` 需谨慎（容易过拟合）
- **类别权重:**
  - 默认 1.0 通常不够（见 1.5 节类别不平衡问题）
  - 建议 class_weight = 10-100

---

### 1.5 自环 (self_loop) - 【关键】

**位置:** `main.py:36`, `src/Clustering.py:44-45`

**限制:** 是否允许自环（同一模式连续出现）需要提前人为设定。

**代码示例:**
```python
# main.py:36
clustering(slice_data, config['self_loop'])  # ← 必须预先设置

# src/Clustering.py:44-45
def clustering(data: list[Slice], self_loop=False):
    # ...
    if not self_loop:
        last_mode = data[i].mode  # 阻止下一段分配到相同模式
```

**技术原因:**
- `self_loop=False` 时，连续的数据段被强制分配到不同模式
- 这是一个**建模假设**，认为系统不会在同一模式停留多个时间段

**影响:** **关键 - 影响模式识别结果**
- **设置错误 (self_loop=False，实际有自环):**
  - 将同一模式的多个段错误分为不同模式
  - 模式数量虚高
  - 守卫条件变得无意义
- **设置错误 (self_loop=True，实际无自环):**
  - 可能将不同模式误合并
  - 模式数量过少

**如何选择:**
- **self_loop=False:** 系统频繁切换，很少在同一模式停留 (如弹跳球)
- **self_loop=True:** 系统可能在同一模式停留较长时间 (如温控系统)
- **不确定时:** 建议 `self_loop=True`（更保守）

---

### 1.6 重置函数 (need_reset) - 【中等】

**位置:** `main.py:37`, `src/GuardLearning.py:26`

**限制:** 是否学习重置函数需要提前人为设定。

**代码示例:**
```python
# src/GuardLearning.py:26
def guard_learning(data: list[Slice], get_feature, config):
    positive_sample = {}
    negative_sample = {}
    slice_data = {}
    need_reset = config['need_reset']  # ← 必须预先设置

    # 如果需要学习重置函数，保存切换前后的数据段
    if need_reset:
        slice_data[idx][0].append(data[i - 1])  # 切换前
        slice_data[idx][1].append(data[i])      # 切换后
```

**重置函数的作用域限制 (src/DE_System.py:40-44):**
```python
# 重置函数仅在转移后的 fit_order 步内有效
if self.reset_fun is None or not self.reset_fun.valid():
    # 使用正常模式动态
    for i in range(self.var_num):
        res.append(np.dot(self.config.get_items(self.state, self.input_data, i),
                          self.eq[i]))
else:
    # 使用重置函数（有限持续时间）
    res = self.reset_fun(self.state, self.input_data, self.var_num)
```

**技术原因:**
- 有些混合系统在模式切换时状态会发生跳变（如碰撞后的速度反转）
- 重置函数学习计算代价较高，且需要足够的转移样本
- 重置函数仅在转移后的短暂时间内生效（fit_order 步）

**影响:** **中等**
- **need_reset=False，实际有重置:**
  - 无法准确模拟转移后的瞬态行为
  - 预测误差在转移后几步较大
- **need_reset=True，实际无重置:**
  - 增加不必要的计算开销
  - 可能过拟合噪声

**如何选择:**
- **need_reset=True:** 系统有明显的跳变（弹跳球、碰撞系统）
- **need_reset=False:** 状态连续演化（温控系统、渐变系统）
- **限制:** 重置函数仅适用于**短暂瞬态**，无法建模长时间复杂重置动态

---

### 1.7 聚类容差比例 (ToleranceRatio) - 【中等】

**位置:** `src/CurveSlice.py:10-19`

**限制:** 聚类时的容差比例硬编码为 0.1 (10%)，无法通过配置文件调整。

**代码示例:**
```python
# src/CurveSlice.py:10-19
class Slice:
    RelativeErrorThreshold = []
    AbsoluteErrorThreshold = []
    ToleranceRatio = 0.1  # ← 固定为 10%，无法修改
    FitErrorThreshold = 1.

@staticmethod
def fit_threshold_one(get_feature, data1, data2):
    """比较两个相邻数据段，校准阈值"""
    # ...
    Slice.FitErrorThreshold = min(Slice.FitErrorThreshold,
                                  max(err) * Slice.ToleranceRatio)  # 使用固定比例
```

**技术原因:**
- 容差比例决定了聚类时的严格程度
- 10% 是经验值，对某些系统可能过严或过松

**影响:** **中等 - 影响聚类结果**
- **比例过小 (<5%):** 过度分割，产生过多模式，相似的段被分开
- **比例过大 (>20%):** 欠分割，不同模式被错误合并

**修改方法:**
如需调整，需修改源代码 `src/CurveSlice.py:12`

---

### 1.8 训练/测试数据分割 - 【中等】

**位置:** `main.py:128`

**限制:** 硬编码为使用最后 6 条轨迹进行训练，前面的轨迹用于测试。

**代码示例:**
```python
# main.py:128
test_num = 6  # 硬编码分割点

evaluation.submit(gt_chp=gt_list[test_num:])
sys, slice_data = run(data[test_num:], input_list[test_num:], config, evaluation)
```

**技术原因:**
- 无交叉验证或随机分割机制
- 假设后面的轨迹代表性更好

**影响:** **中等**
- 结果依赖于特定的轨迹顺序
- 无法进行统计显著性检验
- 无法检测过拟合

**建议:**
使用 k-fold 交叉验证或多次随机分割评估

---

## 二、算法固有约束 (Algorithmic Constraints)

### 2.1 机器精度阈值 (eps) - 【关键】

**位置:** `src/DEConfig.py:77-78`

**限制:** 变点检测的阈值计算为 `1e-6 * dt * max(data)`，系数 `1e-6` 为魔法数字，无理论依据。

**代码示例:**
```python
# src/DEConfig.py:77-78
def get_eps(self, data):
    return 1e-6 * self.dt * np.max(data)  # 1e-6 是经验值
```

**技术原因:**
- 阈值设计目标：足够小以检测真实变点，足够大以抵抗噪声
- `1e-6` 接近浮点运算精度，但对不同系统可能不适用
- `dt * max(data)` 使阈值与时间尺度和数据量级成正比

**影响:** **关键 - 决定变点检测灵敏度**
- **系数过小 (<1e-8):** 极易产生虚假变点，噪声敏感
- **系数过大 (>1e-4):** 遗漏真实变点，检测失败
- **不适用场景:**
  - 状态值极小的系统 (max(data) < 0.01)
  - 高频动态系统
  - 噪声水平高的数据

**改进方向:**
可考虑使用数据的标准差或信噪比动态调整阈值

---

### 2.2 尾部跳过机制 (tail_len) - 【中等】

**位置:** `src/ChangePoints.py:38-41`

**限制:** 检测到变点后，算法跳过接下来的 `w` 个位置，避免重复检测。

**代码示例:**
```python
# src/ChangePoints.py:38-41
if (max(now_err) > eps) and tail_len == 0:
    change_points.append(pos + w - 1)
    tail_len = w  # ← 跳过下个窗口大小的位置
tail_len = max(tail_len - 1, 0)
```

**技术原因:**
- 防止在同一个切换边界重复标记多个变点
- 假设真实变点之间至少间隔 `w` 个时间步

**影响:** **中等**
- **无法处理:**
  - 间隔小于 `w` 的连续切换
  - 抖振 (chattering) 行为
  - 快速多次模式变化
- **示例:** 如果 w=10，两个真实变点间隔 5 步，第二个会被忽略

**适用系统:**
变点间隔 >> 窗口大小的系统

---

### 2.3 最小数据段长度约束 - 【关键】

**位置:** `src/CurveSlice.py:75-79`

**限制:** 数据段长度必须大于 NARX 阶数，否则该段被标记为无效。

**代码示例:**
```python
# src/CurveSlice.py:75-79
if len(data[0]) > get_feature.order:
    self.feature, err, self.fit_order = get_feature(data, input_data)
    self.err = np.max(err)
else:
    # 长度不足，标记为无效
    self.feature, self.err, self.fit_order = [], 1e6, []
    self.valid = False
```

**技术原因:**
- NARX 模型需要至少 `order` 个历史数据点才能拟合
- 最小二乘法要求样本数 > 参数数

**影响:** **关键 - 限制适用系统类型**
- **无法学习:**
  - 持续时间极短的模式 (< order 步)
  - 快速切换系统 (高频切换)
  - 瞬态模式
- **示例:** 如果 order=3，持续时间 ≤3 步的模式无法识别

**解决方案:**
- 降低阶数 (但可能欠拟合)
- 提高采样率
- 不适用于此类系统

---

### 2.4 守卫学习的类别不平衡 - 【关键】

**位置:** `src/GuardLearning.py:17-31`

**限制:** 正样本（转移点）数量远远少于负样本（模式内所有点），类别严重不平衡。

**代码示例:**
```python
# src/GuardLearning.py:17-31

# 正样本：每次转移仅1个点（切换前的最后状态）
positive_sample[idx].append(data[i - 1].data[:, -1])  # 单个时间点

# 负样本：模式内的所有点（除最后一个）
negative_sample[mode].append(np.transpose(data[i].data[:, :-1]))
# 可能有数百个点
```

**不平衡程度示例:**
```
模式 A 持续 100 个时间步，发生 2 次转移到模式 B:
- 正样本 (A→B): 2 个点
- 负样本 (在A但不转移到B): 98 个点
- 不平衡比例: 1:49
```

**技术原因:**
- 系统大部分时间停留在模式内，转移是稀有事件
- 默认 `class_weight` 参数补偿不足

**影响:** **关键 - 导致守卫学习偏差**
- **SVM 偏向多数类:** 倾向于预测"不转移"
- **守卫边界保守:** 守卫条件很少被触发
- **转移延迟或遗漏:** 真实转移点可能无法触发守卫
- **泛化性差:** 对未见过的转移场景识别能力弱

**改进建议:**
- 增大 `class_weight` 参数 (如 10-100)
- 使用 SMOTE 等过采样技术
- 调整 SVM 决策阈值 (当前硬编码为 0.5)

---

### 2.5 守卫独立训练（无全局一致性） - 【中等】

**位置:** `src/GuardLearning.py:38-43`

**限制:** 每条边 (u, v) 的守卫独立训练，不考虑同一源模式的其他守卫。

**代码示例:**
```python
# src/GuardLearning.py:38-43
for (u, v), sample in positive_sample.items():
    svc = SVC(...)  # 每条边独立训练 SVM
    svc.fit(sample, label)
    adj[(u, v)] = (svc, slice_data[(u, v)])
```

**技术原因:**
- 每个守卫是独立的二分类器
- 无多分类形式或一致性约束

**影响:** **中等 - 可能产生不一致的守卫**
- **守卫重叠:** 从模式 u 到 v1 和 v2 的守卫区域可能重叠，非确定性
- **守卫空隙:** 可能存在某些状态无任何守卫满足，造成死锁
- **多守卫同时满足:** 不清楚选择哪个转移

**当前处理机制 (src/HybridAutomata.py:89-109):**
```python
# 遍历所有可能的转移，遇到第一个满足的守卫就转移
for to, fun, reset_val in self.adj.get(self.mode_state, {}):
    if fun(*res):
        # 转移到 to 模式
        break  # 只执行第一个满足的守卫
```

---

### 2.6 聚类方法的差异性 - 【中等】

**位置:** `src/Clustering.py:16-46`

**限制:** 提供两种聚类方法 ('dis' 和 'fit')，选择不同方法可能导致不同的聚类结果。

**代码示例:**
```python
# src/Clustering.py:16-46
if Slice.Method == 'dis':
    # 方法1: 基于参数向量的距离
    for j in range(i):
        if (data[j].mode != last_mode) and (data[i] & data[j]):
            data[i].setMode(data[j].mode)
            break
else:
    # 方法2: 基于 NARX 拟合能力（默认，推荐）
    fit_cnt = 0
    for idx, val in mode_dict.items():
        if idx != last_mode and data[i].test_set(val):
            data[i].mode = idx
            fit_cnt += 1
```

**两种方法对比:**

| 特性 | 距离方法 (`dis`) | 拟合方法 (`fit`) |
|------|-----------------|------------------|
| **判断依据** | 参数向量的 L1 距离 | NARX 模型的可合并性 |
| **理论基础** | 几何距离 | 物理意义（论文定义） |
| **计算复杂度** | 低 O(d) | 中等 O(w·d²) |
| **鲁棒性** | 对噪声敏感 | 对噪声鲁棒 |
| **歧义处理** | 无 | 有（延迟列表） |
| **推荐场景** | 快速原型测试 | 生产环境 |

**影响:** **中等**
- 不同方法可能产生不同的模式数量
- 'dis' 方法可能过度分割
- 'fit' 方法计算慢但更准确

**建议:** 优先使用 `fit` 方法（对应论文理论）

---

## 三、系统建模假设 (System Modeling Assumptions)

### 3.1 完全可观测性假设 - 【关键】

**假设:** 系统的所有状态变量都可以被直接观测和测量。

**位置:** 贯穿整个代码库

**技术原因:**
- NARX 模型形式为 `x[t] = f(x[t-1], ..., x[t-order], u[t])`
- 需要完整的状态历史来构建差分方程
- 无状态估计或滤波机制

**影响:** **关键 - 限制适用系统类型**

**无法处理:**
- **部分可观测系统:** 只能测量部分状态变量
- **隐状态系统:** 存在无法直接观测的内部状态
- **噪声测量:** 需要预先滤波或去噪
- **间接测量:** 需要通过其他量推导状态

**示例:**
```
✓ 可用: 机械臂关节位置和速度都可测量
✗ 不可用: 电路中无法直接测量内部节点电压
✗ 不可用: 生物系统中的内部代谢状态
```

---

### 3.2 NARX 模型适用性假设 - 【关键】

**假设:** 系统动态可以用 NARX 差分方程近似表示。

**NARX 模型形式:**
```
x_i[t] = Σ(a_j · x_i[t-j]) + Σ(b_k · u_k[t]) + Σ(c_l · φ_l(x, u)) + bias
```

**技术原因:**
- NARX 是有限阶、离散时间的表示
- 依赖马尔可夫性假设（未来仅依赖有限历史）

**影响:** **关键 - 决定可建模的系统类型**

**不适用场景:**
- **快速连续时间动态:** 采样率不足导致离散化误差大
- **时滞微分方程:** 延迟时间 >> 采样间隔 × order
- **分布参数系统:** 如偏微分方程（PDE）系统
- **随机微分方程:** 含有布朗运动等随机项
- **复杂跳变动态:** 状态在瞬间发生剧烈变化

**适用条件:**
- 采样定理满足: 采样率 ≥ 2 × 系统最高频率
- 系统满足光滑性要求
- 状态演化相对连续

---

### 3.3 确定性转移假设 - 【关键】

**假设:** 模式转移完全由系统状态决定（守卫条件），是确定性的。

**守卫形式 (src/BuildSystem.py:15):**
```python
def __call__(self, *args):
    return self.model.predict([[*args]])[0] > 0.5  # 确定性阈值
```

**技术原因:**
- SVM 守卫学习假设存在状态空间的分割
- 转移时刻可以通过状态预测

**影响:** **关键 - 限制可建模的转移类型**

**无法建模:**
- **概率转移:** 以一定概率从模式 A 转移到模式 B
- **非确定性行为:** 相同状态可能转移到不同模式
- **定时转移:** 基于时间而非状态的转移 (如"10秒后切换")
- **异步事件:** 外部随机事件触发的转移
- **并发转移:** 多个模式同时激活

**示例:**
```
✓ 可用: 温控系统 (温度 > 25°C → 开启空调)
✗ 不可用: 网络路由 (随机选择路径)
✗ 不可用: 任务调度 (时间片轮转)
```

---

### 3.4 马尔可夫性假设 - 【中等】

**假设:** 系统的未来行为仅依赖于最近 `order` 步的历史状态。

**体现:**
```python
# NARX 模型只使用有限历史
x[t] = f(x[t-1], x[t-2], ..., x[t-order], u[t])
# 不依赖 x[t-order-1] 及更早的状态
```

**影响:** **中等**

**无法捕捉:**
- **长期记忆效应:** 系统行为依赖很久之前的状态
- **路径依赖:** 到达相同状态的不同路径导致不同未来
- **累积效应:** 长期积累的影响（如疲劳、磨损）
- **迟滞 (Hysteresis):** 状态转移依赖历史路径

**解决方案:**
- 增大 `order` (但受限于最小段长度)
- 将迟滞建模为独立的模式

---

### 3.5 分段近似假设 - 【中等】

**假设:** 在每个模式内，系统动态可以用单一的 NARX 模型（线性或指定非线性形式）近似。

**技术原因:**
- 混合自动机的核心思想：全局复杂动态 = 多个局部简单动态的切换
- 每个模式对应一个 NARX 方程

**影响:** **中等**

**局限性:**
- **高度非线性模式:** 需要正确指定非线性项，否则无法拟合
- **时变动态:** 模式内参数随时间变化（如老化系统）
- **连续变化:** 没有明确的模式边界（如渐变系统）

**适用条件:**
- 系统确实具有离散的工作模式
- 每个模式内动态相对稳定
- 非线性形式已知或可推测

---

## 四、数值稳定性问题 (Numerical Stability)

### 4.1 无正则化最小二乘法 - 【中等】

**位置:** `src/DEConfig.py:136`

**限制:** 使用 `np.linalg.lstsq` 进行 NARX 参数拟合，无 L1/L2 正则化。

**代码示例:**
```python
# src/DEConfig.py:136
x = np.linalg.lstsq(a, b, rcond=None)[0]  # 无正则化
res.append(x)
err.append(max(np.abs((a @ x) - b)))
```

**技术原因:**
- 病态矩阵 (ill-conditioned matrix) 导致解不稳定
- 特征共线性导致系数爆炸

**影响:** **中等 - 可能产生数值问题**

**可能的问题:**
- **极大系数:** 参数值达到 1e10 或更高
- **数值溢出/下溢:** 浮点运算超出表示范围
- **预测不稳定:** 小的输入扰动导致大的输出变化
- **过拟合:** 无正则化惩罚导致过度拟合噪声

**易发场景:**
- 非线性项与线性项高度相关
- 采样数据重复或接近重复
- 数据量相对参数数不足

**改进方向:**
使用岭回归 (Ridge) 或 Lasso

---

### 4.2 误差阈值魔法数字 - 【中等】

**位置:** `src/DEConfig.py:116, 139`

**限制:** 阶数选择时使用 `1e-8` 作为停止阈值，无理论依据。

**代码示例:**
```python
# src/DEConfig.py:116, 139
if now_order == self.order or now_err < 1e-8:  # 魔法数字
    res.append(x)
    max_order.append(now_order)
    err.append(now_err)
    break
```

**技术原因:**
- 自动选择 NARX 阶数时，当误差小于阈值则停止增加阶数
- `1e-8` 是经验值，可能对某些系统不适用

**影响:** **中等**
- **阈值过小:** 阶数不必要地增大，过拟合
- **阈值过大:** 阶数过低，欠拟合

**适用性:**
取决于系统噪声水平和数据精度

---

### 4.3 除零保护不足 - 【轻微】

**位置:** `src/CurveSlice.py:23-29`

**限制:** 计算相对距离时使用 `1e-6` 保护，在极端情况下仍可能有数值问题。

**代码示例:**
```python
# src/CurveSlice.py:27
relative_dis = dis / max(d_min, 1e-6)  # 保护除零
```

**影响:** **轻微**
- 状态值极小 (< 1e-10) 时可能出现数值不稳定
- 一般情况下不会遇到

---

## 五、错误处理与验证缺失 (Error Handling Gaps)

### 5.1 输入数据验证缺失 - 【关键】

**位置:** 贯穿整个代码库

**限制:** 无检查 NaN, Inf 或数据质量问题。

**缺失检查:**
- ✗ NaN 值检测
- ✗ Inf 值检测
- ✗ 数据维度一致性验证
- ✗ 采样率合理性检查
- ✗ 数值范围检查

**影响:** **关键 - 导致静默失败**

**可能的后果:**
- 产生错误结果但无警告
- 程序崩溃但错误信息不明确
- 难以调试和定位问题
- 浪费计算资源

**建议添加:**
```python
# 数据验证示例
assert not np.isnan(data).any(), "数据包含 NaN"
assert not np.isinf(data).any(), "数据包含 Inf"
assert data.shape[1] > config['order'], "数据长度不足"
```

---

### 5.2 变点检测结果验证不足 - 【中等】

**位置:** `src/ChangePoints.py`

**限制:** 无检查变点的合理性（如最小间隔、数量上限）。

**缺失检查:**
- ✗ 变点间隔过小 (< order)
- ✗ 变点数量异常 (过多或过少)
- ✗ 变点位置合理性

**影响:** **中等**
- 噪声数据可能产生大量虚假变点
- 无异常检测和警告机制

---

### 5.3 模式验证仅在测试时 - 【中等】

**位置:** `src/BuildSystem.py:42-43`

**限制:** 只在仿真测试时验证模式是否存在，训练时不检查。

**代码示例:**
```python
# src/BuildSystem.py:42-43
if mode_map.get(mode[bias - 1]) is None:
    raise Exception("unknown mode: " + str(mode[bias - 1]))
    # 仅在测试时抛出异常
```

**影响:** **中等**
- 训练时的错误只在测试时才发现
- 增加调试难度

---

### 5.4 守卫一致性验证缺失 - 【中等】

**位置:** `src/GuardLearning.py`

**限制:** 无验证守卫条件是否正确分割状态空间。

**缺失检查:**
- ✗ 守卫重叠检测
- ✗ 守卫空隙检测
- ✗ 可达性分析

**影响:** **中等**
- 可能产生有缺陷的自动机
- 仿真时可能出现死锁或非确定性

---

## 六、可扩展性限制 (Scalability Issues)

### 6.1 聚类二次复杂度 - 【中等】

**位置:** `src/Clustering.py:17-21`

**限制:** 距离方法聚类需要 O(n²) 次比较。

**代码示例:**
```python
# src/Clustering.py:17-21
for i in range(len(data)):  # n 个数据段
    if Slice.Method == 'dis':
        for j in range(i):  # O(n²) 比较
            if (data[j].mode != last_mode) and (data[i] & data[j]):
                data[i].setMode(data[j].mode)
```

**复杂度分析:**
- **距离方法:** O(n²·d)，n 为段数，d 为特征维度
- **拟合方法:** O(n·m·w·d²)，m 为模式数 (通常 m << n)

**影响:** **中等 - 长轨迹处理慢**
- 段数 n > 1000 时速度明显下降
- 无空间索引或近似算法

**缓解方法:**
- 使用 'fit' 方法（复杂度更低）
- 减少轨迹数量或采样点

---

### 6.2 守卫学习内存占用 - 【中等】

**位置:** `src/GuardLearning.py:31`

**限制:** 所有负样本在内存中拼接，可能占用大量内存。

**代码示例:**
```python
# src/GuardLearning.py:31
for (key, val) in negative_sample.items():
    negative_sample[key] = np.concatenate(val)  # 大内存分配
```

**内存估算:**
```
假设:
- 5 个模式，每个平均 200 个时间步
- 10 条轨迹
- 状态维度 = 3

负样本总数 ≈ 5 × 200 × 10 = 10,000 点
内存占用 ≈ 10,000 × 3 × 8 bytes = 240 KB (可接受)

但如果采样率提高 10 倍:
负样本总数 ≈ 100,000 点
内存占用 ≈ 2.4 MB (仍可接受)

极端情况 (长时间、高采样率):
负样本总数 ≈ 1,000,000 点
内存占用 ≈ 24 MB (开始有压力)
```

**影响:** **中等**
- 一般情况下可接受
- 极长轨迹或高维系统可能遇到内存瓶颈

---

### 6.3 无稀疏数据优化 - 【轻微】

**位置:** 贯穿整个代码库

**限制:** 使用密集 numpy 数组，无稀疏矩阵支持。

**影响:** **轻微**
- 高维系统且特征稀疏时效率低
- 大多数混合系统维度不高 (< 10)，影响有限

---

## 七、边界情况与特殊场景 (Edge Cases)

### 7.1 Zeno 行为（循环检测但不阻止） - 【中等】

**位置:** `src/HybridAutomata.py:89-109`

**限制:** 检测到转移循环时仅打印警告，但仍继续执行，可能陷入无限循环。

**代码示例:**
```python
# src/HybridAutomata.py:89-109
while True:
    fl = True
    for to, fun, reset_val in self.adj.get(self.mode_state, {}):
        if fun(*res):
            if to in vis:
                if HybridAutomata.LoopWarning:
                    print("warning: find loop!")  # ← 仅警告
                is_cycle = True  # 标记但继续执行
            # ... 执行转移
```

**技术原因:**
- Zeno 行为：系统在零时间内执行无限多次转移
- 当前实现无超时或最大迭代次数限制

**影响:** **中等**

**可能的问题:**
- 仿真陷入死循环
- 程序无响应
- 无法完成评估

**触发场景:**
- 守卫条件设计错误导致立即满足返回条件
- 重置函数未正确修改状态
- 多个守卫形成循环依赖

**建议:**
添加最大转移次数限制

---

### 7.2 无变点场景 - 【中等】

**位置:** `src/ChangePoints.py`

**限制:** 如果未检测到任何变点，系统仍尝试聚类和守卫学习。

**影响:** **中等**
- 单模式系统产生不必要的复杂性
- 浪费计算资源
- 可能产生无意义的结果

**建议:**
添加早期检测和退出机制

---

### 7.3 无效数据段的处理 - 【中等】

**位置:** `src/CurveSlice.py:65-68`

**限制:** 无效段被标记但未移除，仍参与部分操作。

**代码示例:**
```python
# src/CurveSlice.py:65-68
def check_valid(self):
    if self.valid and self.err > Slice.FitErrorThreshold:
        warnings.warn("Find a invalid segmentation!")
        self.valid = False  # 标记但不删除
```

**影响:** **中等**
- 需要在后续操作中反复检查 `valid` 标志
- 代码逻辑复杂化
- 可能导致错误

---

### 7.4 单模式系统 - 【轻微】

**限制:** 算法假设存在多个模式，单模式系统会产生不必要的开销。

**影响:** **轻微**
- 单模式系统可以正确处理（识别为1个模式）
- 但守卫学习等步骤是多余的

---

## 八、总结与使用指南

### 8.1 算法最适用的场景

✅ **推荐使用条件:**

1. **系统特性:**
   - 具有明确的离散工作模式（2-10个模式）
   - 模式切换频率适中（间隔 > 10×采样间隔）
   - 每个模式持续时间充足（> NARX 阶数）
   - 状态转移基本确定性

2. **数据质量:**
   - 所有状态变量可直接测量
   - 数据干净，噪声水平低
   - 采样率满足奈奎斯特定理
   - 轨迹数量充足（> 5 条）

3. **领域知识:**
   - 系统阶数已知或可估计
   - 非线性形式已知（对非线性系统）
   - 是否有状态跳变（重置）已知

4. **系统类型举例:**
   - ✅ 温控系统（加热/冷却/待机）
   - ✅ 机械碰撞系统（弹跳球）
   - ✅ 电力系统（正常/故障模式）
   - ✅ 简单机器人系统（抓取/移动/放置）

---

### 8.2 算法不适用的场景

❌ **不推荐使用条件:**

1. **系统特性:**
   - 未知系统结构（阶数、非线性未知）
   - 快速切换/抖振系统（Zeno 行为）
   - 极短模式持续时间（< 5 个采样点）
   - 概率或定时转移
   - 高度非线性且非线性形式未知

2. **数据质量:**
   - 部分状态不可观测
   - 噪声水平高
   - 采样率不足
   - 数据量少（< 3 条轨迹）

3. **系统类型举例:**
   - ❌ 高频开关电路（切换太快）
   - ❌ 随机游走系统（非确定性）
   - ❌ 网络协议（定时转移）
   - ❌ 生物神经网络（隐状态多）
   - ❌ 高维稀疏系统（> 20 维）

---

### 8.3 参数调优建议

#### **关键参数优先级 (P0):**

1. **NARX 阶数 (order):**
   - 起始值: 3
   - 调优方法: 网格搜索 [2, 3, 4, 5] + 交叉验证
   - 评估指标: 拟合误差 + 泛化误差

2. **非线性项 (other_items):**
   - 方法: 领域知识 + 符号回归
   - 常用项: `x[1]**2`, `x[1]**3`, `x[1]*x[2]`, `sin(x[1])`
   - 验证: 检查拟合误差是否显著下降

3. **窗口大小 (window_size):**
   - 起始值: 10
   - 调优范围: [max(order+3, 5), 20]
   - 评估: 变点检测准确率

4. **SVM 超参数:**
   - C: 从 1e4 开始，网格搜索 [1e2, 1e4, 1e6]
   - kernel: 优先 'rbf'，线性守卫用 'linear'
   - class_weight: 增大到 10-100 缓解类别不平衡

#### **次要参数 (P1):**

5. **self_loop:** 不确定时设为 True（更保守）
6. **need_reset:** 有明显跳变时设为 True
7. **clustering_method:** 优先 'fit'（更鲁棒）

---

### 8.4 常见问题诊断

| 问题现象 | 可能原因 | 解决方案 |
|---------|---------|---------|
| 模式数过多 | 窗口过小/容差过严 | 增大 window_size |
| 模式数过少 | 窗口过大/容差过松 | 减小 window_size |
| 拟合误差大 | 阶数不足/缺少非线性项 | 增大 order / 添加非线性项 |
| 守卫不触发 | 类别不平衡严重 | 增大 class_weight |
| 计算时间长 | 数据量大/阶数高 | 减少轨迹/降低采样率 |
| 数值不稳定 | 无正则化/病态矩阵 | 检查特征共线性 |

---

### 8.5 扩展与改进方向

**可能的改进点:**

1. **自动参数选择:**
   - AIC/BIC 准则选择 NARX 阶数
   - 网格搜索 + 交叉验证选择 SVM 超参数
   - 自适应窗口大小调整

2. **鲁棒性增强:**
   - 添加正则化到 NARX 拟合
   - SMOTE 过采样缓解类别不平衡
   - 输入数据验证和异常检测

3. **功能扩展:**
   - 支持部分可观测系统（状态估计）
   - 支持概率转移（隐马尔可夫模型）
   - 支持在线/增量学习

4. **性能优化:**
   - 并行化聚类和守卫学习
   - 稀疏矩阵支持
   - GPU 加速

---

## 九、与论文的对应关系

本文档中的限制与论文的关系:

| 论文中的方法 | 实现中的限制 | 影响 |
|------------|------------|------|
| NARX 模板模型 | 阶数和非线性项需人工指定 | 关键 |
| 机器级容忍度 | eps 系数为魔法数字 | 关键 |
| 最小可合并性 | 聚类方法选择影响结果 | 中等 |
| Guard Learning | 类别严重不平衡 | 关键 |
| Reset Learning | 仅适用于短暂瞬态 | 中等 |

---

## 十、参考代码位置索引

方便快速定位关键限制的代码位置:

```
配置依赖:
- NARX 阶数: main.py:33, src/DEConfig.py:67-76
- 窗口大小: src/ChangePoints.py:16-31
- 非线性项: main.py:33, src/DEConfig.py:54-65
- SVM 参数: src/GuardLearning.py:39
- 自环设置: main.py:36, src/Clustering.py:44-45
- 重置学习: src/GuardLearning.py:26, src/DE_System.py:40-44

算法约束:
- 机器精度: src/DEConfig.py:77-78
- 尾部跳过: src/ChangePoints.py:38-41
- 最小段长: src/CurveSlice.py:75-79
- 类别不平衡: src/GuardLearning.py:17-31
- 守卫独立: src/GuardLearning.py:38-43

数值稳定:
- 最小二乘: src/DEConfig.py:136
- 误差阈值: src/DEConfig.py:116, 139
- 除零保护: src/CurveSlice.py:27

边界情况:
- Zeno 循环: src/HybridAutomata.py:89-109
- 无效段: src/CurveSlice.py:65-68
```

---

**文档版本:** 1.0
**最后更新:** 基于代码库当前版本的完整分析
**维护者:** 建议定期更新以反映代码变化
